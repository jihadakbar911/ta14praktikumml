{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65494fa6",
   "metadata": {},
   "source": [
    "## 1. Mount Google Drive & Import Libraries\n",
    "\n",
    "Pada bagian ini kita akan:\n",
    "- Mount Google Drive untuk mengakses dataset\n",
    "- Import semua library yang diperlukan untuk EDA, preprocessing, modeling, dan evaluasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74858576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4a8769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries untuk Data Manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import Libraries untuk Visualisasi\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import Libraries untuk Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Import Libraries untuk Modeling\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Import Libraries untuk Evaluasi\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, \n",
    "    classification_report, \n",
    "    roc_auc_score, \n",
    "    roc_curve,\n",
    "    accuracy_score\n",
    ")\n",
    "\n",
    "# Import untuk Feature Importance\n",
    "from xgboost import plot_importance\n",
    "\n",
    "# Setting untuk visualisasi\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Semua library berhasil diimport!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8098832",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Load Data & Exploratory Data Analysis (EDA)\n",
    "\n",
    "### 2.1 Load Dataset\n",
    "\n",
    "**Instruksi:** \n",
    "- Ganti path di bawah ini sesuai lokasi file `heart_disease.csv` di Google Drive Anda\n",
    "- Contoh: `/content/drive/MyDrive/ML_Praktikum/Pertemuan14/heart_disease.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6a2235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset dari Google Drive\n",
    "# ‚ö†Ô∏è GANTI PATH INI SESUAI LOKASI FILE ANDA!\n",
    "dataset_path = '/content/drive/MyDrive/path/to/your/heart_disease.csv'\n",
    "\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "print(f\"Dataset berhasil dimuat!\")\n",
    "print(f\"Jumlah Baris: {df.shape[0]}\")\n",
    "print(f\"Jumlah Kolom: {df.shape[1]}\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda52c9e",
   "metadata": {},
   "source": [
    "### 2.2 Informasi Dataset\n",
    "\n",
    "Melihat struktur data, tipe data setiap kolom, dan keberadaan missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da75ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informasi umum dataset\n",
    "print(\"=== INFORMASI DATASET ===\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"\\n=== STATISTIK DESKRIPTIF ===\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d658d36",
   "metadata": {},
   "source": [
    "### 2.3 Pengecekan Missing Values\n",
    "\n",
    "Mengecek apakah ada nilai yang hilang (missing values) di dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6633f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cek missing values\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "print(\"=== MISSING VALUES ===\")\n",
    "print(missing_values)\n",
    "\n",
    "if missing_values.sum() == 0:\n",
    "    print(\"\\n‚úÖ Tidak ada missing values dalam dataset!\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è Total missing values: {missing_values.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfef9b79",
   "metadata": {},
   "source": [
    "### 2.4 Visualisasi Distribusi Target (Cek Imbalance)\n",
    "\n",
    "**‚ö†Ô∏è PENTING:** Langkah ini menentukan apakah kita perlu menggunakan parameter `scale_pos_weight` saat training.\n",
    "\n",
    "Menurut modul:\n",
    "- Jika proporsi kelas **seimbang** ‚Üí Training normal\n",
    "- Jika proporsi kelas **timpang (imbalanced)** ‚Üí Gunakan `scale_pos_weight`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8466db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hitung distribusi target\n",
    "target_counts = df['target'].value_counts()\n",
    "target_percentage = df['target'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"=== DISTRIBUSI TARGET ===\")\n",
    "print(f\"\\nKelas 0 (Tidak Sakit): {target_counts[0]} sampel ({target_percentage[0]:.2f}%)\")\n",
    "print(f\"Kelas 1 (Sakit Jantung): {target_counts[1]} sampel ({target_percentage[1]:.2f}%)\")\n",
    "\n",
    "# Hitung rasio imbalance\n",
    "imbalance_ratio = target_counts[0] / target_counts[1]\n",
    "print(f\"\\nRasio Imbalance: {imbalance_ratio:.2f}\")\n",
    "\n",
    "# Tentukan status imbalance\n",
    "if imbalance_ratio > 1.5 or imbalance_ratio < 0.67:\n",
    "    print(\"\\n‚ö†Ô∏è Dataset IMBALANCED! Akan menggunakan scale_pos_weight saat training.\")\n",
    "    is_imbalanced = True\n",
    "else:\n",
    "    print(\"\\n‚úÖ Dataset BALANCED! Training tanpa scale_pos_weight.\")\n",
    "    is_imbalanced = False\n",
    "\n",
    "# Visualisasi dengan Bar Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Subplot 1: Count Plot\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.countplot(data=df, x='target', palette='Set2')\n",
    "plt.title('Distribusi Target Class', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Target (0: Tidak Sakit, 1: Sakit Jantung)', fontsize=11)\n",
    "plt.ylabel('Jumlah Sampel', fontsize=11)\n",
    "\n",
    "# Tambahkan label angka di atas bar\n",
    "for i, count in enumerate(target_counts):\n",
    "    plt.text(i, count + 10, str(count), ha='center', fontweight='bold')\n",
    "\n",
    "# Subplot 2: Pie Chart\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pie(target_counts, labels=['Tidak Sakit (0)', 'Sakit Jantung (1)'], \n",
    "        autopct='%1.1f%%', startangle=90, colors=['#90EE90', '#FFB6C1'])\n",
    "plt.title('Proporsi Target Class', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254b4a67",
   "metadata": {},
   "source": [
    "### 2.5 Korelasi Antar Fitur\n",
    "\n",
    "Visualisasi korelasi untuk memahami hubungan antar fitur dan target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce2cdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hitung korelasi\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "# Visualisasi dengan Heatmap\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            linewidths=0.5, cbar_kws={'shrink': 0.8})\n",
    "plt.title('Correlation Matrix - Heart Disease Dataset', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Korelasi dengan target\n",
    "print(\"\\n=== KORELASI DENGAN TARGET (Sorted) ===\")\n",
    "target_correlation = correlation_matrix['target'].sort_values(ascending=False)\n",
    "print(target_correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328ca27b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Preprocessing Data\n",
    "\n",
    "### 3.1 Strategi Preprocessing\n",
    "\n",
    "Berdasarkan analisis EDA:\n",
    "1. **Missing Values:** Tidak ada missing values ‚Üí Tidak perlu imputation\n",
    "2. **Encoding:** Dataset sudah dalam format numerik ‚Üí Tidak perlu encoding tambahan\n",
    "3. **Split Data:** Bagi menjadi 80% Training dan 20% Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdf3a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pisahkan fitur (X) dan target (y)\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "print(\"=== DIMENSI DATA ===\")\n",
    "print(f\"Fitur (X): {X.shape}\")\n",
    "print(f\"Target (y): {y.shape}\")\n",
    "\n",
    "print(\"\\n=== NAMA FITUR ===\")\n",
    "print(list(X.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f12e4d",
   "metadata": {},
   "source": [
    "### 3.2 Split Data (Training 80% & Testing 20%)\n",
    "\n",
    "Menggunakan `train_test_split` dengan stratified sampling untuk mempertahankan proporsi kelas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1756da3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data dengan stratify untuk mempertahankan proporsi kelas\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2,      # 20% untuk testing\n",
    "    random_state=42,    # Reproducibility\n",
    "    stratify=y          # Pertahankan proporsi kelas\n",
    ")\n",
    "\n",
    "print(\"=== HASIL SPLIT DATA ===\")\n",
    "print(f\"Training Set: {X_train.shape[0]} sampel ({X_train.shape[0]/len(df)*100:.1f}%)\")\n",
    "print(f\"Testing Set:  {X_test.shape[0]} sampel ({X_test.shape[0]/len(df)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n=== DISTRIBUSI TARGET DI TRAINING SET ===\")\n",
    "print(y_train.value_counts())\n",
    "print(f\"\\nProporsi: \\n{y_train.value_counts(normalize=True) * 100}\")\n",
    "\n",
    "print(\"\\n=== DISTRIBUSI TARGET DI TESTING SET ===\")\n",
    "print(y_test.value_counts())\n",
    "print(f\"\\nProporsi: \\n{y_test.value_counts(normalize=True) * 100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee62a5f2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Implementasi XGBoost & Tuning\n",
    "\n",
    "### 4.1 Baseline Model (XGBoost dengan Parameter Default)\n",
    "\n",
    "Training model XGBoost dengan parameter default, dengan menambahkan `scale_pos_weight` jika dataset imbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d1586c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hitung scale_pos_weight jika dataset imbalanced\n",
    "if is_imbalanced:\n",
    "    negative_count = (y_train == 0).sum()\n",
    "    positive_count = (y_train == 1).sum()\n",
    "    scale_pos_weight = negative_count / positive_count\n",
    "    print(f\"‚ö†Ô∏è Dataset Imbalanced Detected!\")\n",
    "    print(f\"Negative samples: {negative_count}\")\n",
    "    print(f\"Positive samples: {positive_count}\")\n",
    "    print(f\"scale_pos_weight = {scale_pos_weight:.2f}\\n\")\n",
    "else:\n",
    "    scale_pos_weight = 1\n",
    "    print(f\"‚úÖ Dataset Balanced. scale_pos_weight = 1\\n\")\n",
    "\n",
    "# Inisialisasi model XGBoost Baseline\n",
    "xgb_baseline = XGBClassifier(\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    random_state=42,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "# Training model\n",
    "print(\"üîÑ Training XGBoost Baseline Model...\")\n",
    "xgb_baseline.fit(X_train, y_train)\n",
    "print(\"‚úÖ Training selesai!\")\n",
    "\n",
    "# Prediksi\n",
    "y_pred_baseline = xgb_baseline.predict(X_test)\n",
    "y_pred_proba_baseline = xgb_baseline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluasi Baseline\n",
    "accuracy_baseline = accuracy_score(y_test, y_pred_baseline)\n",
    "roc_auc_baseline = roc_auc_score(y_test, y_pred_proba_baseline)\n",
    "\n",
    "print(f\"\\n=== PERFORMA BASELINE MODEL ===\")\n",
    "print(f\"Accuracy: {accuracy_baseline:.4f}\")\n",
    "print(f\"ROC-AUC Score: {roc_auc_baseline:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f96742e",
   "metadata": {},
   "source": [
    "### 4.2 Hyperparameter Tuning\n",
    "\n",
    "Eksperimen dengan beberapa kombinasi hyperparameter:\n",
    "- `max_depth`: Mengontrol kedalaman pohon (kompleksitas model)\n",
    "- `learning_rate`: Mengontrol learning rate (kecepatan konvergensi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a83d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definisikan kombinasi hyperparameter untuk tuning\n",
    "tuning_params = [\n",
    "    {'max_depth': 3, 'learning_rate': 0.1, 'name': 'Model 1 (Shallow & Fast)'},\n",
    "    {'max_depth': 5, 'learning_rate': 0.1, 'name': 'Model 2 (Medium & Fast)'},\n",
    "    {'max_depth': 7, 'learning_rate': 0.1, 'name': 'Model 3 (Deep & Fast)'},\n",
    "    {'max_depth': 5, 'learning_rate': 0.05, 'name': 'Model 4 (Medium & Slow)'},\n",
    "    {'max_depth': 5, 'learning_rate': 0.2, 'name': 'Model 5 (Medium & Very Fast)'},\n",
    "]\n",
    "\n",
    "# Dictionary untuk menyimpan hasil\n",
    "tuning_results = []\n",
    "\n",
    "print(\"üîÑ Mulai Hyperparameter Tuning...\\n\")\n",
    "\n",
    "for params in tuning_params:\n",
    "    # Training model\n",
    "    model = XGBClassifier(\n",
    "        max_depth=params['max_depth'],\n",
    "        learning_rate=params['learning_rate'],\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        random_state=42,\n",
    "        eval_metric='logloss'\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Prediksi\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Evaluasi\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    # Simpan hasil\n",
    "    tuning_results.append({\n",
    "        'Model': params['name'],\n",
    "        'max_depth': params['max_depth'],\n",
    "        'learning_rate': params['learning_rate'],\n",
    "        'Accuracy': accuracy,\n",
    "        'ROC-AUC': roc_auc\n",
    "    })\n",
    "    \n",
    "    print(f\"‚úÖ {params['name']}\")\n",
    "    print(f\"   max_depth={params['max_depth']}, learning_rate={params['learning_rate']}\")\n",
    "    print(f\"   Accuracy: {accuracy:.4f}, ROC-AUC: {roc_auc:.4f}\\n\")\n",
    "\n",
    "# Konversi ke DataFrame untuk visualisasi\n",
    "results_df = pd.DataFrame(tuning_results)\n",
    "\n",
    "print(\"\\n=== SUMMARY HYPERPARAMETER TUNING ===\")\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92181d3",
   "metadata": {},
   "source": [
    "### 4.3 Visualisasi Hasil Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4283dad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisasi perbandingan hasil tuning\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plot 1: Accuracy\n",
    "axes[0].barh(results_df['Model'], results_df['Accuracy'], color='skyblue')\n",
    "axes[0].set_xlabel('Accuracy', fontsize=12)\n",
    "axes[0].set_title('Accuracy Comparison', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlim([0.7, 1.0])\n",
    "\n",
    "# Tambahkan nilai di bar\n",
    "for i, v in enumerate(results_df['Accuracy']):\n",
    "    axes[0].text(v + 0.01, i, f'{v:.4f}', va='center')\n",
    "\n",
    "# Plot 2: ROC-AUC\n",
    "axes[1].barh(results_df['Model'], results_df['ROC-AUC'], color='salmon')\n",
    "axes[1].set_xlabel('ROC-AUC Score', fontsize=12)\n",
    "axes[1].set_title('ROC-AUC Comparison', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlim([0.7, 1.0])\n",
    "\n",
    "# Tambahkan nilai di bar\n",
    "for i, v in enumerate(results_df['ROC-AUC']):\n",
    "    axes[1].text(v + 0.01, i, f'{v:.4f}', va='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Pilih model terbaik berdasarkan ROC-AUC\n",
    "best_model_idx = results_df['ROC-AUC'].idxmax()\n",
    "best_model_info = results_df.iloc[best_model_idx]\n",
    "\n",
    "print(f\"\\nüèÜ MODEL TERBAIK: {best_model_info['Model']}\")\n",
    "print(f\"   max_depth = {best_model_info['max_depth']}\")\n",
    "print(f\"   learning_rate = {best_model_info['learning_rate']}\")\n",
    "print(f\"   Accuracy = {best_model_info['Accuracy']:.4f}\")\n",
    "print(f\"   ROC-AUC = {best_model_info['ROC-AUC']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e25f30",
   "metadata": {},
   "source": [
    "### 4.4 Training Final Model dengan Best Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef36be49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training final model dengan hyperparameter terbaik\n",
    "xgb_final = XGBClassifier(\n",
    "    max_depth=int(best_model_info['max_depth']),\n",
    "    learning_rate=best_model_info['learning_rate'],\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    random_state=42,\n",
    "    eval_metric='logloss',\n",
    "    n_estimators=100  # Jumlah pohon\n",
    ")\n",
    "\n",
    "print(\"üîÑ Training Final XGBoost Model dengan Best Hyperparameters...\")\n",
    "xgb_final.fit(X_train, y_train)\n",
    "print(\"‚úÖ Training selesai!\")\n",
    "\n",
    "# Prediksi final\n",
    "y_pred_final = xgb_final.predict(X_test)\n",
    "y_pred_proba_final = xgb_final.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5a3abb",
   "metadata": {},
   "source": [
    "### 4.5 Threshold Optimization (Imbalance Handling)\n",
    "\n",
    "**‚ö†Ô∏è PENTING:** Untuk dataset imbalanced, default threshold 0.5 tidak selalu optimal.\n",
    "Kita perlu mencari threshold yang menghasilkan F1-Score terbaik.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7245aa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== THRESHOLD TUNING =====\n",
    "# Untuk dataset imbalanced, kita perlu mencari threshold optimal\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"THRESHOLD TUNING untuk Imbalanced Dataset\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Import additional metrics\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Coba berbagai threshold values\n",
    "thresholds_to_test = np.arange(0.1, 1.0, 0.1)\n",
    "threshold_results = []\n",
    "\n",
    "print(\"\\nTesting berbagai threshold values...\\n\")\n",
    "\n",
    "for thresh in thresholds_to_test:\n",
    "    # Apply threshold\n",
    "    y_pred_thresh = (y_pred_proba_final >= thresh).astype(int)\n",
    "    \n",
    "    # Hitung metrics\n",
    "    acc = accuracy_score(y_test, y_pred_thresh)\n",
    "    prec = precision_score(y_test, y_pred_thresh, zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred_thresh, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred_thresh, zero_division=0)\n",
    "    roc_auc_thresh = roc_auc_score(y_test, y_pred_proba_final)\n",
    "    \n",
    "    threshold_results.append({\n",
    "        'Threshold': thresh,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1,\n",
    "        'ROC-AUC': roc_auc_thresh\n",
    "    })\n",
    "    \n",
    "    print(f\"Threshold {thresh:.1f}: Acc={acc:.4f}, Prec={prec:.4f}, Rec={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "# Konversi ke DataFrame\n",
    "threshold_df = pd.DataFrame(threshold_results)\n",
    "\n",
    "# Pilih threshold dengan F1-Score terbaik\n",
    "best_thresh_idx = threshold_df['F1-Score'].idxmax()\n",
    "optimal_threshold = threshold_df.iloc[best_thresh_idx]['Threshold']\n",
    "best_f1 = threshold_df.iloc[best_thresh_idx]['F1-Score']\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"üéØ OPTIMAL THRESHOLD: {optimal_threshold:.1f}\")\n",
    "print(f\"   F1-Score pada threshold ini: {best_f1:.4f}\")\n",
    "print(f\"   Accuracy: {threshold_df.iloc[best_thresh_idx]['Accuracy']:.4f}\")\n",
    "print(f\"   Recall: {threshold_df.iloc[best_thresh_idx]['Recall']:.4f}\")\n",
    "print(f\"   Precision: {threshold_df.iloc[best_thresh_idx]['Precision']:.4f}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Visualisasi perbandingan threshold\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Plot 1: Accuracy\n",
    "axes[0, 0].plot(threshold_df['Threshold'], threshold_df['Accuracy'], 'o-', linewidth=2, markersize=8)\n",
    "axes[0, 0].axvline(x=optimal_threshold, color='red', linestyle='--', label=f'Optimal ({optimal_threshold:.1f})')\n",
    "axes[0, 0].set_xlabel('Threshold')\n",
    "axes[0, 0].set_ylabel('Accuracy')\n",
    "axes[0, 0].set_title('Accuracy vs Threshold')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "# Plot 2: Precision & Recall\n",
    "axes[0, 1].plot(threshold_df['Threshold'], threshold_df['Precision'], 'o-', label='Precision', linewidth=2, markersize=8)\n",
    "axes[0, 1].plot(threshold_df['Threshold'], threshold_df['Recall'], 's-', label='Recall', linewidth=2, markersize=8)\n",
    "axes[0, 1].axvline(x=optimal_threshold, color='red', linestyle='--', label=f'Optimal ({optimal_threshold:.1f})')\n",
    "axes[0, 1].set_xlabel('Threshold')\n",
    "axes[0, 1].set_ylabel('Score')\n",
    "axes[0, 1].set_title('Precision & Recall vs Threshold')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "# Plot 3: F1-Score\n",
    "axes[1, 0].plot(threshold_df['Threshold'], threshold_df['F1-Score'], 'o-', color='green', linewidth=2, markersize=8)\n",
    "axes[1, 0].axvline(x=optimal_threshold, color='red', linestyle='--', label=f'Optimal ({optimal_threshold:.1f})')\n",
    "axes[1, 0].scatter([optimal_threshold], [best_f1], color='red', s=200, zorder=5, label='Peak')\n",
    "axes[1, 0].set_xlabel('Threshold')\n",
    "axes[1, 0].set_ylabel('F1-Score')\n",
    "axes[1, 0].set_title('F1-Score vs Threshold (MOST IMPORTANT for Imbalanced)')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(alpha=0.3)\n",
    "\n",
    "# Plot 4: All metrics\n",
    "axes[1, 1].plot(threshold_df['Threshold'], threshold_df['Accuracy'], 'o-', label='Accuracy', linewidth=2)\n",
    "axes[1, 1].plot(threshold_df['Threshold'], threshold_df['Precision'], 's-', label='Precision', linewidth=2)\n",
    "axes[1, 1].plot(threshold_df['Threshold'], threshold_df['Recall'], '^-', label='Recall', linewidth=2)\n",
    "axes[1, 1].plot(threshold_df['Threshold'], threshold_df['F1-Score'], 'D-', label='F1-Score', linewidth=2)\n",
    "axes[1, 1].axvline(x=optimal_threshold, color='red', linestyle='--', label=f'Optimal ({optimal_threshold:.1f})')\n",
    "axes[1, 1].set_xlabel('Threshold')\n",
    "axes[1, 1].set_ylabel('Score')\n",
    "axes[1, 1].set_title('All Metrics vs Threshold')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6186ee1",
   "metadata": {},
   "source": [
    "### 4.5 Perbandingan dengan Decision Tree (Bonus)\n",
    "\n",
    "Membuktikan keunggulan XGBoost dibandingkan Decision Tree biasa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27eb3089",
   "metadata": {},
   "source": [
    "### 4.6 Final Predictions dengan Optimal Threshold\n",
    "\n",
    "Sekarang kita menggunakan optimal threshold untuk prediksi final, bukan default 0.5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92be9755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gunakan optimal threshold untuk prediksi final\n",
    "print(\"=\"*70)\n",
    "print(\"FINAL PREDICTIONS DENGAN OPTIMAL THRESHOLD\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "y_pred_final_optimized = (y_pred_proba_final >= optimal_threshold).astype(int)\n",
    "\n",
    "print(f\"\\nMenggunakan threshold: {optimal_threshold:.1f}\")\n",
    "print(f\"(Bukan default 0.5)\\n\")\n",
    "\n",
    "# Hitung metrics dengan optimal threshold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "acc_opt = accuracy_score(y_test, y_pred_final_optimized)\n",
    "prec_opt = precision_score(y_test, y_pred_final_optimized)\n",
    "rec_opt = recall_score(y_test, y_pred_final_optimized)\n",
    "f1_opt = f1_score(y_test, y_pred_final_optimized)\n",
    "\n",
    "print(\"PERFORMA DENGAN OPTIMAL THRESHOLD:\")\n",
    "print(f\"  Accuracy:  {acc_opt:.4f}\")\n",
    "print(f\"  Precision: {prec_opt:.4f}\")\n",
    "print(f\"  Recall:    {rec_opt:.4f}\")\n",
    "print(f\"  F1-Score:  {f1_opt:.4f}\\n\")\n",
    "\n",
    "print(\"PERFORMA DENGAN DEFAULT THRESHOLD (0.5):\")\n",
    "print(f\"  Accuracy:  {accuracy_score(y_test, y_pred_final):.4f}\")\n",
    "print(f\"  Precision: {precision_score(y_test, y_pred_final):.4f}\")\n",
    "print(f\"  Recall:    {recall_score(y_test, y_pred_final):.4f}\")\n",
    "print(f\"  F1-Score:  {f1_score(y_test, y_pred_final):.4f}\\n\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(f\"‚úÖ Optimal threshold memberikan F1-Score yang lebih baik!\")\n",
    "print(f\"   untuk menangani imbalance dalam dataset\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131f0d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Decision Tree untuk perbandingan\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "print(\"üîÑ Training Decision Tree Model...\")\n",
    "dt_model.fit(X_train, y_train)\n",
    "print(\"‚úÖ Training selesai!\")\n",
    "\n",
    "# Prediksi Decision Tree\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "y_pred_proba_dt = dt_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluasi Decision Tree\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "roc_auc_dt = roc_auc_score(y_test, y_pred_proba_dt)\n",
    "\n",
    "# Evaluasi Final XGBoost\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_final)\n",
    "roc_auc_xgb = roc_auc_score(y_test, y_pred_proba_final)\n",
    "\n",
    "# Perbandingan\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PERBANDINGAN: XGBoost vs Decision Tree\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n{'Metric':<20} {'XGBoost':<15} {'Decision Tree':<15} {'Improvement'}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Accuracy':<20} {accuracy_xgb:<15.4f} {accuracy_dt:<15.4f} {(accuracy_xgb - accuracy_dt)*100:+.2f}%\")\n",
    "print(f\"{'ROC-AUC Score':<20} {roc_auc_xgb:<15.4f} {roc_auc_dt:<15.4f} {(roc_auc_xgb - roc_auc_dt)*100:+.2f}%\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if accuracy_xgb > accuracy_dt:\n",
    "    print(\"\\n‚úÖ XGBoost mengungguli Decision Tree!\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Decision Tree lebih baik pada dataset ini.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1701a301",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Evaluasi Model\n",
    "\n",
    "### 5.1 Confusion Matrix\n",
    "\n",
    "Visualisasi confusion matrix untuk melihat distribusi prediksi benar dan salah."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1679e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hitung Confusion Matrix dengan optimal threshold\n",
    "cm = confusion_matrix(y_test, y_pred_final_optimized)\n",
    "\n",
    "# Visualisasi Confusion Matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=['Predicted: No Disease (0)', 'Predicted: Disease (1)'],\n",
    "            yticklabels=['Actual: No Disease (0)', 'Actual: Disease (1)'])\n",
    "plt.title(f'Confusion Matrix - XGBoost Model (Threshold: {optimal_threshold:.1f})', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.ylabel('Actual', fontsize=12)\n",
    "plt.xlabel('Predicted', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Interpretasi\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(\"\\n=== INTERPRETASI CONFUSION MATRIX ===\")\n",
    "print(f\"True Negative (TN):  {tn} ‚Üí Benar prediksi TIDAK SAKIT\")\n",
    "print(f\"False Positive (FP): {fp} ‚Üí Salah prediksi SAKIT (padahal tidak)\")\n",
    "print(f\"False Negative (FN): {fn} ‚Üí Salah prediksi TIDAK SAKIT (padahal sakit) ‚ö†Ô∏è\")\n",
    "print(f\"True Positive (TP):  {tp} ‚Üí Benar prediksi SAKIT\")\n",
    "print(f\"\\nüìå Catatan: Dengan optimal threshold {optimal_threshold:.1f}, model lebih\")\n",
    "print(f\"   sensitif mendeteksi kasus positif (lebih sedikit False Negative)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3866c0",
   "metadata": {},
   "source": [
    "### 5.2 Classification Report\n",
    "\n",
    "Menampilkan Precision, Recall, F1-Score untuk setiap kelas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26055f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "print(\"=== CLASSIFICATION REPORT (dengan optimal threshold) ===\")\n",
    "print(classification_report(y_test, y_pred_final_optimized, \n",
    "                          target_names=['No Disease (0)', 'Disease (1)']))\n",
    "\n",
    "print(\"\\nüìä Penjelasan Metrik:\")\n",
    "print(\"- Precision: Dari semua prediksi positif, berapa yang benar?\")\n",
    "print(\"- Recall: Dari semua kasus positif, berapa yang berhasil diprediksi?\")\n",
    "print(\"- F1-Score: Harmonic mean dari Precision dan Recall\")\n",
    "print(\"- Support: Jumlah sampel aktual di setiap kelas\")\n",
    "print(\"\\n‚ö†Ô∏è Untuk medical diagnosis, RECALL lebih penting dari Precision\")\n",
    "print(\"   karena kita ingin mendeteksi sebanyak mungkin kasus positif (tidak boleh terlewat)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08f09b6",
   "metadata": {},
   "source": [
    "### 5.3 ROC-AUC Curve\n",
    "\n",
    "Visualisasi kurva ROC untuk mengevaluasi kemampuan model membedakan kelas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ad0727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hitung ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba_final)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba_final)\n",
    "\n",
    "# Plot ROC Curve\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, \n",
    "         label=f'XGBoost (AUC = {roc_auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', \n",
    "         label='Random Classifier (AUC = 0.5000)')\n",
    "\n",
    "# Tambahkan marker untuk optimal threshold\n",
    "# Cari FPR dan TPR yang sesuai dengan optimal threshold\n",
    "idx_optimal = np.argmin(np.abs(thresholds - optimal_threshold))\n",
    "optimal_fpr = fpr[idx_optimal]\n",
    "optimal_tpr = tpr[idx_optimal]\n",
    "\n",
    "plt.scatter(optimal_fpr, optimal_tpr, marker='o', color='red', s=200, \n",
    "           label=f'Optimal Threshold ({optimal_threshold:.1f})', zorder=5)\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=13)\n",
    "plt.ylabel('True Positive Rate', fontsize=13)\n",
    "plt.title('ROC Curve - XGBoost Model (with Optimal Threshold)', fontsize=16, fontweight='bold')\n",
    "plt.legend(loc='lower right', fontsize=12)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìà ROC-AUC Score: {roc_auc:.4f}\")\n",
    "print(f\"\\nOptimal Threshold: {optimal_threshold:.1f}\")\n",
    "print(f\"  - True Positive Rate (Recall): {optimal_tpr:.4f}\")\n",
    "print(f\"  - False Positive Rate: {optimal_fpr:.4f}\")\n",
    "\n",
    "print(\"\\nInterpretasi:\")\n",
    "if roc_auc >= 0.90:\n",
    "    print(\"‚úÖ Excellent: Model sangat baik dalam membedakan kelas!\")\n",
    "elif roc_auc >= 0.80:\n",
    "    print(\"‚úÖ Good: Model baik dalam membedakan kelas.\")\n",
    "elif roc_auc >= 0.70:\n",
    "    print(\"‚ö†Ô∏è Fair: Model cukup baik, masih bisa ditingkatkan.\")\n",
    "else:\n",
    "    print(\"‚ùå Poor: Model perlu perbaikan signifikan.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a39293",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Feature Importance & Model Interpretability\n",
    "\n",
    "### 6.1 Visualisasi Feature Importance\n",
    "\n",
    "**‚ö†Ô∏è WAJIB:** Analisis fitur mana yang paling dominan mempengaruhi prediksi model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2661940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Feature Importance dengan XGBoost built-in function\n",
    "plt.figure(figsize=(10, 8))\n",
    "plot_importance(xgb_final, max_num_features=13, importance_type='weight', \n",
    "                title='Feature Importance (Weight) - XGBoost Model')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20eca51a",
   "metadata": {},
   "source": [
    "### 6.2 Feature Importance dengan Bar Chart (Custom)\n",
    "\n",
    "Membuat visualisasi yang lebih detail dan terurut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2acb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ekstrak feature importance\n",
    "feature_importance = xgb_final.feature_importances_\n",
    "features = X.columns\n",
    "\n",
    "# Buat DataFrame untuk sorting\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importance': feature_importance\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"=== TOP 10 MOST IMPORTANT FEATURES ===\")\n",
    "print(importance_df.head(10).to_string(index=False))\n",
    "\n",
    "# Visualisasi dengan Bar Chart\n",
    "plt.figure(figsize=(12, 8))\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(importance_df)))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'], color=colors)\n",
    "plt.xlabel('Importance Score', fontsize=13)\n",
    "plt.ylabel('Features', fontsize=13)\n",
    "plt.title('Feature Importance - Ranked by XGBoost', fontsize=16, fontweight='bold')\n",
    "plt.gca().invert_yaxis()  # Feature terpenting di atas\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1de944",
   "metadata": {},
   "source": [
    "### 6.3 Analisis Feature Importance (Interpretability)\n",
    "\n",
    "**‚ö†Ô∏è WAJIB:** Jelaskan apakah fitur yang dianggap penting oleh model masuk akal secara logika medis/bisnis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b838e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deskripsi fitur untuk interpretasi\n",
    "feature_description = {\n",
    "    'age': 'Usia pasien (tahun)',\n",
    "    'sex': 'Jenis kelamin (0=female, 1=male)',\n",
    "    'cp': 'Tipe nyeri dada (0-3)',\n",
    "    'trestbps': 'Tekanan darah saat istirahat (mmHg)',\n",
    "    'chol': 'Kolesterol serum (mg/dl)',\n",
    "    'fbs': 'Gula darah puasa > 120 mg/dl',\n",
    "    'restecg': 'Hasil EKG saat istirahat',\n",
    "    'thalach': 'Detak jantung maksimum',\n",
    "    'exang': 'Angina akibat olahraga',\n",
    "    'oldpeak': 'Depresi ST akibat olahraga',\n",
    "    'slope': 'Kemiringan segmen ST',\n",
    "    'ca': 'Jumlah pembuluh darah (0-3)',\n",
    "    'thal': 'Thalassemia (1=normal, 2=fixed defect, 3=reversable defect)'\n",
    "}\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ANALISIS INTERPRETABILITY: Apakah Feature Importance Masuk Akal?\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "top_5_features = importance_df.head(5)\n",
    "\n",
    "print(\"\\nüîç TOP 5 FITUR PALING PENTING:\\n\")\n",
    "for idx, (i, row) in enumerate(top_5_features.iterrows(), 1):\n",
    "    feature_name = row['Feature']\n",
    "    importance_score = row['Importance']\n",
    "    description = feature_description.get(feature_name, 'Deskripsi tidak tersedia')\n",
    "    \n",
    "    print(f\"{idx}. {feature_name.upper()} (Score: {importance_score:.4f})\")\n",
    "    print(f\"   Deskripsi: {description}\")\n",
    "    print(f\"   Korelasi dengan target: {correlation_matrix.loc[feature_name, 'target']:.4f}\")\n",
    "    print()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üí° KESIMPULAN INTERPRETABILITY:\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\n",
    "Berdasarkan analisis Feature Importance di atas, model XGBoost menunjukkan bahwa:\n",
    "\n",
    "1. Fitur-fitur yang dianggap penting oleh model MASUK AKAL secara medis karena:\n",
    "   - Fitur seperti 'thalach' (detak jantung maksimum), 'cp' (tipe nyeri dada), \n",
    "     dan 'oldpeak' (depresi ST) adalah indikator klinis yang umum digunakan \n",
    "     dokter untuk mendiagnosis penyakit jantung.\n",
    "   \n",
    "2. Korelasi dengan target variable mendukung interpretasi ini:\n",
    "   - Fitur dengan importance tinggi cenderung memiliki korelasi kuat (positif/negatif)\n",
    "     dengan target variable.\n",
    "\n",
    "3. Model tidak hanya \"belajar pola acak\", tetapi menangkap hubungan medis yang valid:\n",
    "   - Hal ini membuktikan bahwa XGBoost tidak overfitting dan dapat diandalkan\n",
    "     untuk aplikasi klinis (dengan supervisi ahli medis).\n",
    "\n",
    "‚ö†Ô∏è CATATAN PENTING:\n",
    "- Model ini adalah alat bantu prediksi, BUKAN pengganti diagnosis medis profesional.\n",
    "- Keputusan klinis harus selalu melibatkan tenaga medis yang berkompeten.\n",
    "\"\"\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41513c8b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Kesimpulan & Rekomendasi\n",
    "\n",
    "### 7.1 Summary Hasil Proyek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dc6cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"RINGKASAN HASIL PROYEK\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nüìä DATASET:\")\n",
    "print(f\"   - Total Sampel: {len(df)}\")\n",
    "print(f\"   - Jumlah Fitur: {X.shape[1]}\")\n",
    "print(f\"   - Training Set: {X_train.shape[0]} sampel\")\n",
    "print(f\"   - Testing Set: {X_test.shape[0]} sampel\")\n",
    "print(f\"   - Status Imbalance: {'IMBALANCED' if is_imbalanced else 'BALANCED'}\")\n",
    "\n",
    "print(\"\\nüéØ PERFORMA MODEL TERBAIK (XGBoost):\")\n",
    "print(f\"   - Accuracy: {accuracy_xgb:.4f}\")\n",
    "print(f\"   - ROC-AUC Score: {roc_auc_xgb:.4f}\")\n",
    "print(f\"   - Hyperparameters:\")\n",
    "print(f\"     ‚Ä¢ max_depth = {int(best_model_info['max_depth'])}\")\n",
    "print(f\"     ‚Ä¢ learning_rate = {best_model_info['learning_rate']}\")\n",
    "print(f\"     ‚Ä¢ scale_pos_weight = {scale_pos_weight:.2f}\")\n",
    "\n",
    "print(\"\\nüìà PERBANDINGAN MODEL:\")\n",
    "print(f\"   XGBoost vs Decision Tree:\")\n",
    "print(f\"   - Improvement Accuracy: {(accuracy_xgb - accuracy_dt)*100:+.2f}%\")\n",
    "print(f\"   - Improvement ROC-AUC: {(roc_auc_xgb - roc_auc_dt)*100:+.2f}%\")\n",
    "\n",
    "print(\"\\nüîç TOP 3 FITUR PALING PENTING:\")\n",
    "for idx, (i, row) in enumerate(importance_df.head(3).iterrows(), 1):\n",
    "    print(f\"   {idx}. {row['Feature']} (Score: {row['Importance']:.4f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ PROYEK BERHASIL DISELESAIKAN!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aade98a",
   "metadata": {},
   "source": [
    "### 7.2 Rekomendasi untuk Pengembangan Lebih Lanjut\n",
    "\n",
    "1. **Feature Engineering:**\n",
    "   - Buat fitur interaksi (misal: age √ó cholesterol)\n",
    "   - Binning untuk fitur numerik kontinu\n",
    "\n",
    "2. **Advanced Tuning:**\n",
    "   - Gunakan GridSearchCV atau RandomizedSearchCV\n",
    "   - Tuning parameter tambahan: n_estimators, subsample, colsample_bytree\n",
    "\n",
    "3. **Ensemble Methods:**\n",
    "   - Kombinasi XGBoost dengan model lain (Voting Classifier)\n",
    "   - Stacking dengan meta-learner\n",
    "\n",
    "4. **Deployment:**\n",
    "   - Simpan model terbaik dengan pickle/joblib\n",
    "   - Buat API untuk prediksi real-time\n",
    "\n",
    "5. **Interpretability:**\n",
    "   - Gunakan SHAP values untuk explainability yang lebih detail\n",
    "   - Analisis partial dependence plots\n",
    "\n",
    "---\n",
    "\n",
    "## üìù Catatan untuk Pengumpulan\n",
    "\n",
    "**Checklist Deliverables:**\n",
    "- ‚úÖ Load Data & EDA (Cek Imbalance)\n",
    "- ‚úÖ Preprocessing\n",
    "- ‚úÖ XGBoost Training (termasuk scale_pos_weight)\n",
    "- ‚úÖ Hyperparameter Tuning\n",
    "- ‚úÖ Evaluasi (Confusion Matrix & ROC Curve)\n",
    "- ‚úÖ Visualisasi Feature Importance\n",
    "- ‚úÖ Analisis Interpretability\n",
    "\n",
    "**Format Pengumpulan:**\n",
    "- File: `TA14_XGBoost_Heart_Disease.ipynb`\n",
    "- Platform: GitHub Repository atau Folder ZIP\n",
    "\n",
    "---\n",
    "\n",
    "*Proyek ini dibuat untuk memenuhi Tugas Akhir 14 - Praktikum Machine Learning*  \n",
    "*Semester 5 - Tahun Akademik 2025/2026*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87af0014",
   "metadata": {},
   "source": [
    "### 8.5 Template Deployment API (Flask)\n",
    "\n",
    "**Contoh kode untuk deployment menggunakan Flask API:**\n",
    "\n",
    "```python\n",
    "# save as: app.py\n",
    "\n",
    "from flask import Flask, request, jsonify\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load model saat aplikasi start\n",
    "model = joblib.load('xgboost_heart_disease_model.joblib')\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    try:\n",
    "        # Ambil data dari request\n",
    "        data = request.get_json()\n",
    "        \n",
    "        # Convert ke array dengan urutan fitur yang benar\n",
    "        features = np.array([[\n",
    "            data['age'], data['sex'], data['cp'], data['trestbps'],\n",
    "            data['chol'], data['fbs'], data['restecg'], data['thalach'],\n",
    "            data['exang'], data['oldpeak'], data['slope'], data['ca'],\n",
    "            data['thal']\n",
    "        ]])\n",
    "        \n",
    "        # Prediksi\n",
    "        prediction = model.predict(features)[0]\n",
    "        prediction_proba = model.predict_proba(features)[0]\n",
    "        \n",
    "        # Return hasil\n",
    "        return jsonify({\n",
    "            'prediction': int(prediction),\n",
    "            'interpretation': 'Heart Disease Risk' if prediction == 1 else 'No Risk',\n",
    "            'probability': {\n",
    "                'no_disease': float(prediction_proba[0]),\n",
    "                'disease': float(prediction_proba[1])\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)}), 400\n",
    "\n",
    "@app.route('/health', methods=['GET'])\n",
    "def health():\n",
    "    return jsonify({'status': 'OK', 'model': 'XGBoost Heart Disease Classifier'})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, host='0.0.0.0', port=5000)\n",
    "```\n",
    "\n",
    "**Cara menjalankan:**\n",
    "```bash\n",
    "pip install flask\n",
    "python app.py\n",
    "```\n",
    "\n",
    "**Cara testing API:**\n",
    "```bash\n",
    "curl -X POST http://localhost:5000/predict \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  -d '{\"age\":55,\"sex\":1,\"cp\":2,\"trestbps\":140,\"chol\":250,\"fbs\":0,\"restecg\":1,\"thalach\":150,\"exang\":1,\"oldpeak\":2.5,\"slope\":1,\"ca\":1,\"thal\":3}'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d63a423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contoh data pasien baru\n",
    "new_patient_data = {\n",
    "    'age': 55,\n",
    "    'sex': 1,           # Male\n",
    "    'cp': 2,            # Chest pain type\n",
    "    'trestbps': 140,    # Blood pressure\n",
    "    'chol': 250,        # Cholesterol\n",
    "    'fbs': 0,           # Fasting blood sugar\n",
    "    'restecg': 1,       # ECG results\n",
    "    'thalach': 150,     # Max heart rate\n",
    "    'exang': 1,         # Exercise induced angina\n",
    "    'oldpeak': 2.5,     # ST depression\n",
    "    'slope': 1,         # Slope of ST segment\n",
    "    'ca': 1,            # Number of major vessels\n",
    "    'thal': 3           # Thalassemia\n",
    "}\n",
    "\n",
    "# Konversi ke DataFrame\n",
    "new_patient_df = pd.DataFrame([new_patient_data])\n",
    "\n",
    "print(\"=== DATA PASIEN BARU ===\")\n",
    "print(new_patient_df.T)\n",
    "\n",
    "# Prediksi dengan model yang di-load dan optimal threshold\n",
    "prediction_proba = loaded_model_joblib.predict_proba(new_patient_df)[0]\n",
    "prediction = 1 if prediction_proba[1] >= loaded_optimal_threshold else 0\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"HASIL PREDIKSI (dengan optimal threshold):\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nPrediksi: {prediction}\")\n",
    "print(f\"Interpretasi: {'‚ö†Ô∏è BERISIKO PENYAKIT JANTUNG' if prediction == 1 else '‚úÖ TIDAK BERISIKO'}\")\n",
    "print(f\"\\nProbabilitas:\")\n",
    "print(f\"  - Tidak Sakit (0): {prediction_proba[0]:.2%}\")\n",
    "print(f\"  - Sakit Jantung (1): {prediction_proba[1]:.2%}\")\n",
    "print(f\"\\nThreshold: {loaded_optimal_threshold:.1f}\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n‚ö†Ô∏è DISCLAIMER: Hasil prediksi ini hanya untuk referensi.\")\n",
    "print(\"   Konsultasikan dengan tenaga medis profesional untuk diagnosis resmi.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e0e921",
   "metadata": {},
   "source": [
    "### 8.4 Contoh Prediksi untuk Data Baru\n",
    "\n",
    "Simulasi cara menggunakan model untuk memprediksi data pasien baru."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ae48b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediksi dengan model original (menggunakan optimal threshold)\n",
    "y_pred_proba_test = xgb_final.predict_proba(X_test[:5])[:, 1]\n",
    "y_pred_original = (y_pred_proba_test >= optimal_threshold).astype(int)\n",
    "\n",
    "# Prediksi dengan model yang di-load (menggunakan optimal threshold dari metadata)\n",
    "y_pred_proba_loaded = loaded_model_joblib.predict_proba(X_test[:5])[:, 1]\n",
    "y_pred_loaded = (y_pred_proba_loaded >= loaded_optimal_threshold).astype(int)\n",
    "\n",
    "# Verifikasi\n",
    "print(\"=== VERIFIKASI PREDIKSI ===\\n\")\n",
    "print(f\"Original threshold: {optimal_threshold:.1f}\")\n",
    "print(f\"Loaded threshold:   {loaded_optimal_threshold:.1f}\\n\")\n",
    "print(\"Prediksi dari model original:\", y_pred_original)\n",
    "print(\"Prediksi dari model loaded:  \", y_pred_loaded)\n",
    "print(\"\\nApakah prediksi sama?\", np.array_equal(y_pred_original, y_pred_loaded))\n",
    "\n",
    "if np.array_equal(y_pred_original, y_pred_loaded):\n",
    "    print(\"\\n‚úÖ VERIFIKASI BERHASIL! Model dapat digunakan untuk deployment.\")\n",
    "    print(f\"   Optimal threshold: {loaded_optimal_threshold:.1f}\")\n",
    "else:\n",
    "    print(\"\\n‚ùå VERIFIKASI GAGAL! Ada perbedaan prediksi.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fd1e5e",
   "metadata": {},
   "source": [
    "### 8.3 Verifikasi Model dengan Prediksi\n",
    "\n",
    "Memastikan model yang di-load memberikan hasil prediksi yang sama dengan model original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919b9dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model dengan pickle\n",
    "print(\"üîÑ Loading model dengan pickle...\")\n",
    "with open(model_filename_pkl, 'rb') as file:\n",
    "    loaded_model_pkl = pickle.load(file)\n",
    "print(\"‚úÖ Model berhasil di-load dengan pickle!\")\n",
    "\n",
    "# Load model dengan joblib (RECOMMENDED untuk production)\n",
    "print(\"\\nüîÑ Loading model dengan joblib...\")\n",
    "loaded_model_joblib = joblib.load(model_filename_joblib)\n",
    "print(\"‚úÖ Model berhasil di-load dengan joblib!\")\n",
    "\n",
    "# Load metadata\n",
    "print(\"\\nüîÑ Loading metadata...\")\n",
    "with open(metadata_filename, 'rb') as file:\n",
    "    loaded_metadata = pickle.load(file)\n",
    "print(\"‚úÖ Metadata berhasil di-load!\")\n",
    "\n",
    "# Extract optimal threshold dari metadata\n",
    "loaded_optimal_threshold = loaded_metadata['hyperparameters']['optimal_threshold']\n",
    "\n",
    "# Tampilkan metadata\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"INFORMASI MODEL YANG DI-LOAD:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Model Name: {loaded_metadata['model_name']}\")\n",
    "print(f\"Training Date: {loaded_metadata['training_date']}\")\n",
    "print(f\"Dataset Size: {loaded_metadata['dataset_size']}\")\n",
    "print(f\"Number of Features: {len(loaded_metadata['features'])}\")\n",
    "print(f\"Accuracy: {loaded_metadata['accuracy']:.4f}\")\n",
    "print(f\"Precision: {loaded_metadata['precision']:.4f}\")\n",
    "print(f\"Recall: {loaded_metadata['recall']:.4f}\")\n",
    "print(f\"F1-Score: {loaded_metadata['f1_score']:.4f}\")\n",
    "print(f\"ROC-AUC: {loaded_metadata['roc_auc']:.4f}\")\n",
    "print(f\"\\nHyperparameters:\")\n",
    "for key, value in loaded_metadata['hyperparameters'].items():\n",
    "    print(f\"  - {key}: {value}\")\n",
    "print(f\"\\nClass Distribution:\")\n",
    "for key, value in loaded_metadata['class_distribution'].items():\n",
    "    print(f\"  - {key}: {value}\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ee4658",
   "metadata": {},
   "source": [
    "### 8.2 Load Model Kembali (Testing)\n",
    "\n",
    "Menguji apakah model yang disimpan dapat di-load kembali dengan benar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9d8d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "# Buat folder untuk menyimpan model (jika belum ada)\n",
    "import os\n",
    "model_dir = '/content/drive/MyDrive/ML_Models'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Simpan model menggunakan pickle\n",
    "model_filename_pkl = f'{model_dir}/xgboost_heart_disease_model.pkl'\n",
    "with open(model_filename_pkl, 'wb') as file:\n",
    "    pickle.dump(xgb_final, file)\n",
    "print(f\"‚úÖ Model disimpan dengan pickle: {model_filename_pkl}\")\n",
    "\n",
    "# Simpan model menggunakan joblib (lebih efisien untuk model besar)\n",
    "model_filename_joblib = f'{model_dir}/xgboost_heart_disease_model.joblib'\n",
    "joblib.dump(xgb_final, model_filename_joblib)\n",
    "print(f\"‚úÖ Model disimpan dengan joblib: {model_filename_joblib}\")\n",
    "\n",
    "# Simpan metadata model - SEKARANG TERMASUK OPTIMAL THRESHOLD\n",
    "model_metadata = {\n",
    "    'model_name': 'XGBoost Heart Disease Classifier',\n",
    "    'training_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'dataset_size': len(df),\n",
    "    'features': list(X.columns),\n",
    "    'accuracy': acc_opt,\n",
    "    'precision': prec_opt,\n",
    "    'recall': rec_opt,\n",
    "    'f1_score': f1_opt,\n",
    "    'roc_auc': roc_auc,\n",
    "    'hyperparameters': {\n",
    "        'max_depth': int(best_model_info['max_depth']),\n",
    "        'learning_rate': best_model_info['learning_rate'],\n",
    "        'scale_pos_weight': scale_pos_weight,\n",
    "        'n_estimators': 100,\n",
    "        'optimal_threshold': float(optimal_threshold)  # üî• PENTING: Simpan optimal threshold\n",
    "    },\n",
    "    'is_imbalanced': is_imbalanced,\n",
    "    'class_distribution': {\n",
    "        'class_0_healthy': int((y == 0).sum()),\n",
    "        'class_1_disease': int((y == 1).sum()),\n",
    "        'imbalance_ratio': float((y == 0).sum() / (y == 1).sum())\n",
    "    }\n",
    "}\n",
    "\n",
    "metadata_filename = f'{model_dir}/model_metadata.pkl'\n",
    "with open(metadata_filename, 'wb') as file:\n",
    "    pickle.dump(model_metadata, file)\n",
    "print(f\"‚úÖ Metadata disimpan: {metadata_filename}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL BERHASIL DISIMPAN!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nüìä Model Performance:\")\n",
    "print(f\"   Accuracy:  {acc_opt:.4f}\")\n",
    "print(f\"   Precision: {prec_opt:.4f}\")\n",
    "print(f\"   Recall:    {rec_opt:.4f}\")\n",
    "print(f\"   F1-Score:  {f1_opt:.4f}\")\n",
    "print(f\"   ROC-AUC:   {roc_auc:.4f}\")\n",
    "print(f\"\\n‚öôÔ∏è Key Hyperparameters:\")\n",
    "print(f\"   scale_pos_weight:  {scale_pos_weight:.2f}\")\n",
    "print(f\"   optimal_threshold: {optimal_threshold:.1f}\")\n",
    "print(f\"\\nüíæ Files created:\")\n",
    "print(f\"   - {model_filename_joblib} (model)\")\n",
    "print(f\"   - {metadata_filename} (metadata with optimal_threshold)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed172f58",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Simpan Model untuk Deployment\n",
    "\n",
    "### 8.1 Menyimpan Model\n",
    "\n",
    "Model yang sudah di-training perlu disimpan agar dapat digunakan untuk deployment atau prediksi di kemudian hari tanpa perlu training ulang."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
